{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk, re, time, math, sys, os, glob, json\n",
    "import nltk\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29315\n"
     ]
    }
   ],
   "source": [
    "# find all the json files in the directory and provides the path to the files\n",
    "matches = dict()\n",
    "words = {} # place the words you would like to match on hear\n",
    "files = set()\n",
    "import glob\n",
    "c = 0\n",
    "for file in glob.iglob('**/*.json', recursive=True):\n",
    "    c+=1\n",
    "    files.add(file)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchWords(text_to_search, words_to_search):\n",
    "    words = nltk.word_tokenize(text_to_search)\n",
    "    for x in words_to_search:\n",
    "        for syn in wordnet.synsets(x):\n",
    "            for synoyms in syn.lemmas():\n",
    "                if synoyms.name() in words:\n",
    "                    return True\n",
    "        if x in words:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method takes roughly 6 minutes in this state for me to run right now on my laptop\n",
    "output = {}\n",
    "start = time.time()\n",
    "for file in files:\n",
    "    with open(file, \"r\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "    del data['metadata']\n",
    "    id = data['paper_id']\n",
    "    del data['paper_id']\n",
    "    del data['ref_entries']\n",
    "    del data['bib_entries']\n",
    "    del data['back_matter']\n",
    "    output[file] = {}\n",
    "    for section in data:\n",
    "        output[file][section] = {}\n",
    "        for paragraph in range(len(data[section])):\n",
    "            if searchWords(data[section][paragraph]['text'], \"virus\"): \n",
    "                print(data[section][paragraph]['text'])\n",
    "                output[file][section][paragraph] = data[section][paragraph]['text']\n",
    "            print(section, paragraph)\n",
    "    break # just for testing purposes\n",
    "print(\"Time: {}\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(output, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
